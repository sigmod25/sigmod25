# Artifact for Verifying DeSCO

## Experiment Setup
1. Download and unzip the compressed file `DeSCO.tar.gz`
2. Entering the folder `DeSCO`

### Install dependencies
1. Install [SBT](https://www.scala-sbt.org/1.x/docs/Setup.html)
2. Install [Python](https://www.python.org)
3. Install [NPM](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm), and run `npm install` in the test folder (./smart_contracts_evaluation).
4. Install [Ganache](https://trufflesuite.com/ganache/): npm install -g ganache
5. Install [Truffle](https://trufflesuite.com/docs/truffle/how-to/install/): npm install -g truffle

## Reproduce experiment results
**Notice:** all the bash scripts are written for Linux environment. If you are using Windows or Mac system, some bash commands may need to be changed to work successfully.

**Notice:** To get the consistent results, develpers should use the same testing data for all the benchmarks. And if you delete the data, next time our testing script would detect it and generate a new set of testing data, which may lead into a minor difference in the testing value. However, these minor differences would not affect the analysis and conclusion of our work.

### Run all at once
1.Open one terminal to run Ganache:
```
ganache -a 10 -p 8545 --logging.debug
```
2.Open another terminal to run the bash file `run.sh`.

All the evaluation results will be output to the terminal directly, and also be stored in the `tracefiles folder`(./smart\_contracts\_evaluation/tracefiles\_long/). 

To find the results of a specific transaction of a given contract, enter the subfolder of contract (e.g., `auction`(./smart\_contracts\_evaluation/tracefiles\_long/auction)), and then the subfolder of transaction (e.g., `bid` (./smart\_contracts\_evaluation/tracefiles\_long/auction/bid)). The files named **opcode** contain the results and have three types: a. file names ending with "min" and numbers => results for different versions under different materialization plans generated by DeSCO; b. file names ending with "full" => results for incremental datalog without applying optimization techqniques; c. file names ending with "ref" => results for reference.

Normally, the overall time for getting all results would be less than one hour, which can be conducted on a personal computer or virtual machine. However, due to cases like a bad network condition, the tests may need more time to finish, which even leads to the error of exceeding the gas limit of Ganache. In this case, find a place with good network conditions and reopen ganache to rerun the tests.


### Run step by step

#### A. Generate materialization plans:
1. Generate Datalog metadata:
```
cd declarative-smart-contracts
sbt "run dependency-graph"
sbt "run judgement-check"
```
2. Move the `generated metadata(contain-judgement, relation-dependencies)`(./declarative-smart-contracts/view-materialization) into `alogrithm folder`(./gasOpt-setGeneration/view-materialization).
3. Generate materialization plans:
```
cd gasOpt-setGeneration
python3 ./full-set.py
python3 ./min-set.py
```

#### B. Compile Datalog into Solidity
1. Move the `full materialization plan`(./gasOpt-setGeneration/view-materialization/full-set) and `minimal materialization plan`(./gasOpt-setGeneration/view-materialization/min-set) into `compiler foler`(./declarative-smart-contracts/view-materialization).
2. Generate Solidity of Incremential Datalog and minimal versions
```
cd declarative-smart-contracts
./generateNoOptimization.sh
./generateMin.sh
```

### C. Run experiments and get results
1. Move and formalize the name of the `generated Solidity`(./declarative-smart-contracts/solidity) into `test folder`(./smart_contracts_evaluation/contracts) by running `moveContract.sh`
2. Open Ganache: ```ganache -a 10 -p 8545 --logging.debug```
3. Compile and run test for a single contract:
```
cd smart_contracts_evaluation
./test.sh <name_of_the_contract>
```
For example, to run experiment for auction, run `./test.sh auction`.

## Supplementary materials
Appendix for detailed proof for some lemma and theorem used in the paper: `CompleteProof.pdf`.

Evaluation results: see in `evaluation_results.xlsx`.
